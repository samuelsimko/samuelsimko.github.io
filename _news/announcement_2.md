---
layout: post
date: 2025-06-24 16:11:00-0400
inline: true
related_posts: false
---
I have given a talk at the Zurich AI Alignment (ZAIA) on jailbreaking LLMs and why it matters for AI safety.
You can find the slides [here](https://docs.google.com/presentation/d/1TbgtLl2ZTFpW9nHRjy6KbkaRmMNDVz5qiE47ApKL_6k/edit?usp=sharing).
